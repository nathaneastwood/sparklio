% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/spark_query_data.R
\name{spark_query_data}
\alias{spark_query_data}
\title{Query a Spark DataFrame}
\usage{
spark_query_data(sc, x, type = c("lazy", "compute", "collect"), name = NULL)
}
\arguments{
\item{sc}{A \code{spark_connection}.}

\item{x}{A SQL query.}

\item{type}{\code{character(1)}. One of "lazy", "compute" or "collect". See
details for more.}

\item{name}{\code{character(1)}. The name to be given to the Spark DataFrame if
\code{type} is not \code{collect} (default: \code{NULL}).}
}
\value{
One of two:
\enumerate{
\item A \code{tbl_spark} reference to a Spark DataFrame in the event \code{type} is
compute or lazy
\item A \code{data.frame} in the event \code{type} is collect.
}
}
\description{
Query a Spark DataFrame and optionally return the results to Spark memory or
to R's memory.
}
\details{
This function differs depending on the \code{type} given by the user. There are
three scenarios:
\enumerate{
\item The default, \code{"lazy"}, ensures that the query is registered within the
spark context but it is only evaluated, for example when the user collects
the data (see \code{\link[=spark_pull_df]{spark_pull_df()}} or \code{\link[sparklyr:collect]{sparklyr::collect()}}).
\item \code{"compute"} ensures that the query is executed and the resulting data are
stored within Spark's memory.
\item \code{"collect"} executes the query and returns the resulting data to R's
memory.
}
}
